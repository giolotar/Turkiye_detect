{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyO47d447sVKEVI/EmouXJsk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giolotar/Turkiye_detect/blob/main/Inference_Runner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Turkey Detect: Inference Runner**"
      ],
      "metadata": {
        "id": "mipGA6y2WN_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The following code loads a pretrained model with weights and configuration**\n",
        "\n",
        "The model was trained on the rubble instances of a single sat image of Antakya, Turkyie. Annotations were made in CVAT with one label \"Damage\" = \"Rubble\n",
        "The model weights and configuration are loaded and assembled into a predictor."
      ],
      "metadata": {
        "id": "qZtEQRjFWZGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The predictor then ingests a tif image, tiles it, runs predictions on the tiles, based on that predictions it does two things:\n",
        "\n",
        "\n",
        "\n",
        "1.   Generates a masks file .npz with the bounding boxes, coordinates and confidence grade for each prediction. the file which is then used to make a shapefile that is georeferenced to the injected tif\n",
        "2.   Generates a simple png image with the printed masks on it\n",
        "\n"
      ],
      "metadata": {
        "id": "5SqLf-81W0fV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SET-UP**"
      ],
      "metadata": {
        "id": "lfFCxhAFXrZ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44CaW_qRvXB2"
      },
      "outputs": [],
      "source": [
        "#Mount up the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Detectron2 Library\n",
        "!python -m pip install pyyaml==5.1\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "metadata": {
        "id": "HP6IyM8czlAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU Check\n",
        "\n",
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ],
      "metadata": {
        "id": "fpp663Az5KAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQ7HdUtkPWaI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# Detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load the Model and Config**\n",
        "\n",
        "Here we load a pretrained model configuration and weights"
      ],
      "metadata": {
        "id": "PPVu1FzuYGTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cfg_pretrained = get_cfg()\n",
        "\n",
        "saved_config_path = \"/content/drive/MyDrive/colabDL/turkey_OGrun.yaml\"\n",
        "saved_weights_path = \"/content/drive/MyDrive/colabDL/tile1/model_final_cfg2.pth\"\n",
        "\n",
        "# Load the configuration directly from your saved .yaml file\n",
        "try:\n",
        "    cfg_pretrained.merge_from_file(saved_config_path)\n",
        "except KeyError as e:\n",
        "    print(f\"Error loading configuration from {saved_config_path}: {e}\")\n",
        "    raise\n",
        "\n",
        "# Set the path to the model weights\n",
        "cfg_pretrained.MODEL.WEIGHTS = saved_weights_path\n",
        "\n",
        "# Ensure the output directory is created (needed for the predictor)\n",
        "cfg_pretrained.OUTPUT_DIR = \"/content/sample_data\"\n",
        "os.makedirs(cfg_pretrained.OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "SYTihJmqtzhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Compile Predictor**"
      ],
      "metadata": {
        "id": "fV5KR3FjYvjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Threshold\n",
        "cfg_pretrained.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3\n",
        "\n",
        "# Assemble predictor\n",
        "predictor = DefaultPredictor(cfg_pretrained)\n",
        "\n",
        "print(\"DefaultPredictor initialized successfully with loaded configuration and weights.\")"
      ],
      "metadata": {
        "id": "6QZfxHSgYXJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Predict on a Single Tile (Test)**\n",
        "\n",
        "Try to predict on a Test image / tile to check if the predictor works. This would require you have a splitted test database with tiles"
      ],
      "metadata": {
        "id": "-bzr4oopfkrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "\n",
        "# Directory containing the test tiles\n",
        "TEST_TILES_DIR = \"/content/drive/MyDrive/colabDL/tile1/test_row1to6_8\"\n",
        "\n",
        "# List all files in the directory\n",
        "tile_filenames = [f for f in os.listdir(TEST_TILES_DIR) if f.endswith('.tif') or f.endswith('.png') or f.endswith('.jpg')] # Add other image extensions if needed\n",
        "\n",
        "if not tile_filenames:\n",
        "    print(f\"No image files found in the directory: {TEST_TILES_DIR}\")\n",
        "else:\n",
        "    # Select a random filename\n",
        "    random_tile_filename = random.choice(tile_filenames)\n",
        "    random_tile_path = os.path.join(TEST_TILES_DIR, random_tile_filename)\n",
        "\n",
        "    print(f\"Loading random tile: {random_tile_filename}\")\n",
        "\n",
        "    # Read the random tile image\n",
        "    new_im = cv2.imread(random_tile_path)\n",
        "\n",
        "    if new_im is None:\n",
        "        print(f\"Error: Could not read image at {random_tile_path}. Please check the file path and ensure it's a valid image.\")\n",
        "    else:\n",
        "        # Ensure the image is in the correct format (e.g., 3 channels) if necessary for the predictor\n",
        "        if len(new_im.shape) == 2: # If grayscale\n",
        "            new_im = cv2.cvtColor(new_im, cv2.COLOR_GRAY2BGR)\n",
        "        elif new_im.shape[2] == 4: # If RGBA\n",
        "            new_im = new_im[:, :, :3] # Drop alpha channel\n",
        "\n",
        "\n",
        "        outputs  = predictor(new_im)\n",
        "\n",
        "        # We can use `Visualizer` to draw the predictions on the image.\n",
        "\n",
        "#!!! NEED TO EXPLORE WITH VISUALIZER OPTIONS MORE APPEALING MASKS REPRESENTATIONS\n",
        "v = Visualizer(new_im[:, :, ::-1], metadata=None)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "cv2_imshow(out.get_image()[:, :, ::-1]) # Convert back to RGB for displaying"
      ],
      "metadata": {
        "id": "krbzoGG0iKLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference**\n",
        "\n",
        "Then we run the predictor on an unseen Georeferenced TIF image, the image gets tiled, predictions are run on the tiles and exported in .npz as georeferenced polygons.\n",
        "Then they are turned into a shapefile"
      ],
      "metadata": {
        "id": "bex9MRnxWrwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Shapefile with predicted instances as Georeferenced Polygons"
      ],
      "metadata": {
        "id": "EygAnXpPW1e_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65cee5f4"
      },
      "source": [
        "!pip install rasterio fiona shapely"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tile_tiff_save_preds.py\n",
        "import os\n",
        "import math\n",
        "import cv2\n",
        "import numpy as np\n",
        "import rasterio # Import rasterio for georeferenced image handling\n",
        "\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog  # needed for Visualizer\n",
        "\n",
        "# ==== USER PATHS ====\n",
        "INPUT_TIFF = \"/content/drive/MyDrive/colabDL/Turkiye/TR1/1_GEOTIFF.tif\" # Use the georeferenced TIFF\n",
        "OUT_DIR   = \"/content/drive/MyDrive/colabDL/Turkiye/TR1\"  # main output directory\n",
        "NPZ_OUT_DIR = os.path.join(OUT_DIR, \"npz_preds\") # subdirectory for npz files\n",
        "TILE = 1024\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "os.makedirs(NPZ_OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Read the georeferenced image and get georeferencing info\n",
        "try:\n",
        "    with rasterio.open(INPUT_TIFF) as src:\n",
        "        img = src.read()\n",
        "        # Rasterio reads bands first (C, H, W), convert to OpenCV format (H, W, C)\n",
        "        img = np.transpose(img, (1, 2, 0))\n",
        "        # Explicitly select the first 3 channels to handle potential alpha channels\n",
        "        if img.shape[2] == 4:\n",
        "            img = img[:, :, :3]\n",
        "        orig_h, orig_w = img.shape[:2]\n",
        "        transform = src.transform # Affine transform for georeferencing\n",
        "        crs = src.crs # Coordinate reference system\n",
        "\n",
        "except rasterio.errors.RasterioIOError as e:\n",
        "    raise FileNotFoundError(f\"Could not read georeferenced image at {INPUT_TIFF}: {e}\")\n",
        "\n",
        "# Pad to multiples of TILE so we don’t lose right/bottom edges\n",
        "H = math.ceil(orig_h / TILE) * TILE\n",
        "W = math.ceil(orig_w / TILE) * TILE\n",
        "pad_bottom = H - orig_h\n",
        "pad_right  = W - orig_w\n",
        "\n",
        "if pad_bottom or pad_right:\n",
        "    # Use the last pixel value for padding to avoid edge effects if possible,\n",
        "    # otherwise use black padding for color images.\n",
        "    if img.shape[2] == 3:\n",
        "        pad_val = [int(img[-1,-1,0]), int(img[-1,-1,1]), int(img[-1,-1,2])]\n",
        "    else:\n",
        "        pad_val = [0] * img.shape[2]\n",
        "    img = cv2.copyMakeBorder(\n",
        "        img, 0, pad_bottom, 0, pad_right,\n",
        "        borderType=cv2.BORDER_CONSTANT, value=pad_val\n",
        "    )\n",
        "\n",
        "rows = H // TILE\n",
        "cols = W // TILE\n",
        "\n",
        "tiles_written = 0\n",
        "dets_saved = 0\n",
        "\n",
        "for y in range(rows):\n",
        "    for x in range(cols):\n",
        "        r0 = y * TILE\n",
        "        c0 = x * TILE\n",
        "        tile = img[r0:r0+TILE, c0:c0+TILE]\n",
        "\n",
        "        # Calculate georeferenced origin of the tile (top-left corner)\n",
        "        geo_x0, geo_y0 = transform * (c0, r0)\n",
        "\n",
        "        # ---- Run inference on the tile\n",
        "        outputs = predictor(tile)\n",
        "        inst = outputs[\"instances\"].to(\"cpu\")\n",
        "\n",
        "        # ---- Extract raw predictions\n",
        "        boxes  = inst.pred_boxes.tensor.numpy() if inst.has(\"pred_boxes\") else np.zeros((0,4), dtype=np.float32)\n",
        "        scores = inst.scores.numpy()             if inst.has(\"scores\")     else np.zeros((0,), dtype=np.float32)\n",
        "        classes= inst.pred_classes.numpy()       if inst.has(\"pred_classes\") else np.zeros((0,), dtype=np.int32)\n",
        "        masks  = inst.pred_masks.numpy()         if inst.has(\"pred_masks\") else None  # (N, H, W) boolean\n",
        "\n",
        "        # ---- SAVE RAW PREDICTIONS (compressed)\n",
        "        # Include tile origin in pixel and georeferenced coordinates\n",
        "        npz_path = os.path.join(NPZ_OUT_DIR, f\"tile_{y}_{x}_pred.npz\")\n",
        "        np.savez_compressed(\n",
        "            npz_path,\n",
        "            boxes=boxes,\n",
        "            scores=scores,\n",
        "            classes=classes,\n",
        "            masks=masks,                 # None is allowed; np.load(..., allow_pickle=True) will handle it\n",
        "            tile_row=y,\n",
        "            tile_col=x,\n",
        "            tile_origin_rc=np.array([r0, c0], dtype=np.int32), # Pixel origin (row, col)\n",
        "            tile_origin_geo=np.array([geo_x0, geo_y0], dtype=np.float64), # Georeferenced origin (x, y)\n",
        "            tile_size=TILE,\n",
        "            padded_h=H,\n",
        "            padded_w=W,\n",
        "            orig_h=orig_h,\n",
        "            orig_w=orig_w,\n",
        "            pad_bottom=pad_bottom,\n",
        "            pad_right=pad_right\n",
        "        )\n",
        "        dets_saved += len(boxes)\n",
        "\n",
        "print(f\"Done. Wrote {tiles_written} visualized tiles to {OUT_DIR}\")\n",
        "print(f\"Saved predictions for {rows*cols} tiles ({dets_saved} detections total) as .npz files to {NPZ_OUT_DIR}\")"
      ],
      "metadata": {
        "id": "cHUiBpUR5Rr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert from the npz to shp retaining geographic coordinates"
      ],
      "metadata": {
        "id": "xdXEnh2vUGjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "import rasterio\n",
        "from shapely.geometry import Polygon, mapping\n",
        "import fiona"
      ],
      "metadata": {
        "id": "MszJ1WCOUK-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory containing the predicted tile .npz files\n",
        "PREDICTED_NPZ_DIR = \"/content/drive/MyDrive/colabDL/Turkiye/TR1/npz_preds\" # Assuming npz files are in a subdirectory\n",
        "\n",
        "# Output shapefile/geopackage path\n",
        "# Changed to .gpkg for geopackage, which is preferred\n",
        "OUTPUT_VECTOR_PATH = \"/content/drive/MyDrive/colabDL/Turkiye/TR1/Rubble_1.gpkg\"\n",
        "\n",
        "# Path to the original georeferenced image (GeoTIFF or similar)\n",
        "\n",
        "# This is necessary to get the coordinate system and transform information.\n",
        "ORIGINAL_GEOREFERENCED_IMAGE_PATH = \"/content/drive/MyDrive/colabDL/Turkiye/TR1/1_GEOTIFF.tif\" # Example path, replace with your actual georeferenced image path\n",
        "\n",
        "# --- Function to get georeferencing information ---\n",
        "def get_georeferencing_info(image_path):\n",
        "    \"\"\"Reads georeferencing information (transform and CRS) from a georeferenced image.\"\"\"\n",
        "    try:\n",
        "        with rasterio.open(image_path) as src:\n",
        "            return src.transform, src.crs\n",
        "    except rasterio.errors.RasterioIOError as e:\n",
        "        print(f\"Error reading georeferencing info from {image_path}: {e}\")\n",
        "        print(\"Assuming pixel coordinates. The output vector file will NOT be georeferenced.\")\n",
        "        return None, None\n",
        "\n",
        "# Get georeferencing info from the original image\n",
        "transform, crs = get_georeferencing_info(ORIGINAL_GEOREFERENCED_IMAGE_PATH)\n",
        "\n",
        "# --- Define the schema for the vector file ---\n",
        "# This defines the attributes (columns) for each feature (polygon) in the vector file.\n",
        "# We'll include score and class_id from the predictions.\n",
        "schema = {\n",
        "    'geometry': 'Polygon',\n",
        "    'properties': {'score': 'float', 'class_id': 'int'},\n",
        "}\n",
        "\n",
        "# --- Create the vector file (Geopackage) ---\n",
        "# Determine the driver based on the output file extension\n",
        "# Changed driver to GPKG for Geopackage\n",
        "driver = 'GPKG'\n",
        "\n",
        "# Open the vector file in write mode\n",
        "# If a CRS was obtained, use it. Otherwise, the vector file will have no defined CRS.\n",
        "with fiona.open(\n",
        "    OUTPUT_VECTOR_PATH,\n",
        "    'w',\n",
        "    driver,\n",
        "    schema,\n",
        "    crs=crs # Use the obtained CRS, or None if not available\n",
        ") as collection:\n",
        "    # List all .npz files in the directory\n",
        "    npz_filenames = [f for f in os.listdir(PREDICTED_NPZ_DIR) if f.endswith('_pred.npz')]\n",
        "\n",
        "    if not npz_filenames:\n",
        "        print(\"No predicted .npz files found in the directory.\")\n",
        "    else:\n",
        "        # Iterate through each .npz file\n",
        "        for filename in npz_filenames:\n",
        "            npz_path = os.path.join(PREDICTED_NPZ_DIR, filename)\n",
        "            with np.load(npz_path, allow_pickle=True) as data:\n",
        "                masks = data['masks']\n",
        "                scores = data['scores']\n",
        "                classes = data['classes']\n",
        "                tile_origin_rc = data['tile_origin_rc'] # Pixel origin (r0, c0)\n",
        "                # tile_origin_geo = data['tile_origin_geo'] # Georeferenced origin (x0, y0) - not directly used here but available\n",
        "\n",
        "                if masks is not None and masks.shape[0] > 0:\n",
        "                    # Process each instance mask within the tile\n",
        "                    for i in range(masks.shape[0]):\n",
        "                        instance_mask = masks[i]\n",
        "                        score = scores[i]\n",
        "                        class_id = classes[i]\n",
        "\n",
        "                        # Find contours of the mask\n",
        "                        # cv2.findContours requires a single-channel binary image\n",
        "                        # Ensure instance_mask is uint8 and binary (0 or 255)\n",
        "                        mask_uint8 = instance_mask.astype(np.uint8) * 255\n",
        "                        # Use cv2.RETR_TREE and cv2.CHAIN_APPROX_NONE for more detailed contours if needed,\n",
        "                        # but SIMPLE is usually sufficient for polygons.\n",
        "                        contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                        # Convert contours to polygons and transform coordinates\n",
        "                        for contour in contours:\n",
        "                            # Reshape contour to be a list of points (x, y)\n",
        "                            # Contour points are in tile coordinates (pixel within the tile)\n",
        "                            # Ensure points are in (x, y) format which corresponds to (column, row)\n",
        "                            contour_points_tile = contour.squeeze().tolist()\n",
        "\n",
        "                            if not isinstance(contour_points_tile, list):\n",
        "                                # Handle cases where contour.squeeze() results in a single point\n",
        "                                contour_points_tile = [contour_points_tile]\n",
        "                            elif not all(isinstance(p, list) for p in contour_points_tile):\n",
        "                                # Handle cases where contour.squeeze() results in a flat list of coords\n",
        "                                contour_points_tile = [contour_points_tile]\n",
        "\n",
        "\n",
        "                            if len(contour_points_tile) < 3:\n",
        "                                continue # Skip if not enough points to form a polygon\n",
        "\n",
        "                            # Convert tile pixel coordinates to padded image pixel coordinates\n",
        "                            # Tile origin is (row, col), contour points are (col, row)\n",
        "                            contour_points_padded = [(p[0] + tile_origin_rc[1], p[1] + tile_origin_rc[0]) for p in contour_points_tile]\n",
        "\n",
        "                            # Convert padded image pixel coordinates to geographic coordinates using the original image's transform\n",
        "                            if transform:\n",
        "                                # Apply the affine transform to each point\n",
        "                                # transform * (col, row) gives (x, y) georeferenced coordinates\n",
        "                                contour_points_geo = [transform * (p[0], p[1]) for p in contour_points_padded]\n",
        "                                polygon = Polygon(contour_points_geo)\n",
        "                            else:\n",
        "                                # If no transform, use padded pixel coordinates for the polygon\n",
        "                                polygon = Polygon(contour_points_padded)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                                # Add the polygon and its properties to the vector file\n",
        "                            if not polygon.is_empty and polygon.exterior: # Ensure polygon is valid and not empty\n",
        "                                # Cast score to a standard float type to potentially avoid Fiona warning\n",
        "                                collection.write({\n",
        "                                    'geometry': mapping(polygon),\n",
        "                                    'properties': {'score': float(score), 'class_id': int(class_id)},\n",
        "                                })\n",
        "\n",
        "print(f\"Vector file (Geopackage) saved to {OUTPUT_VECTOR_PATH}\")"
      ],
      "metadata": {
        "id": "9iOIBvZq9XBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Produce a .TIF image mosaic with the predictions and bounding boxes printed on the image."
      ],
      "metadata": {
        "id": "SCqAzQ2FhVTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#use npz to create a geotiff\n",
        "# tile_tiff_save_preds.py (mosaic a single GeoTIFF with printed predictions FROM .npz files)\n",
        "import os\n",
        "import math\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.enums import ColorInterp\n",
        "\n",
        "# ==== USER PATHS ====\n",
        "INPUT_TIFF = \"/content/drive/MyDrive/colabDL/Turkiye/TR1/1_GEOTIFF.tif\"  # original georeferenced image\n",
        "OUT_DIR    = \"/content/drive/MyDrive/colabDL/Turkiye/TR1/Rubble_2_tif\"   # output directory\n",
        "OUTPUT_GEOTIFF = os.path.join(OUT_DIR, \"Rubble_1_predictions_vis.tif\")   # final mosaic GeoTIFF\n",
        "PREDICTED_NPZ_DIR = \"/content/drive/MyDrive/colabDL/Turkiye/TR1/npz_preds\"  # folder with *_pred.npz\n",
        "TILE = 1024  # only used for padding convenience; actual tile size taken from npz masks\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def color_from_class_id(class_id: int) -> tuple:\n",
        "    \"\"\"\n",
        "    Deterministic, visually distinct color per class_id.\n",
        "    Returns (B, G, R) for OpenCV drawing.\n",
        "    \"\"\"\n",
        "    rng = np.random.RandomState(class_id * 1337 + 42)\n",
        "    return tuple(int(x) for x in rng.choice(256, size=3))  # BGR\n",
        "\n",
        "def put_label(img, text, pt, bg=(0,0,0), fg=(255,255,255)):\n",
        "    \"\"\"\n",
        "    Draw label with filled background for readability.\n",
        "    img: HxWx3 uint8 (BGR)\n",
        "    pt: (x, y) bottom-left anchor\n",
        "    \"\"\"\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    scale = 0.5\n",
        "    thickness = 1\n",
        "    (tw, th), baseline = cv2.getTextSize(text, font, scale, thickness)\n",
        "    x, y = pt\n",
        "    cv2.rectangle(img, (x, y - th - baseline), (x + tw, y + baseline), bg, -1, cv2.LINE_AA)\n",
        "    cv2.putText(img, text, (x, y), font, scale, fg, thickness, cv2.LINE_AA)\n",
        "\n",
        "# ---------- visualization config (ADD THIS) ----------\n",
        "USE_FIXED_COLOR = True                # force one color for all instances\n",
        "FIXED_COLOR_BGR = (0, 0, 255)         # red in BGR\n",
        "ALPHA = 0.45                          # mask fill opacity\n",
        "DRAW_BBOX = True                      # draw bounding boxes\n",
        "LABEL_OFFSET = (2, 12)                # (x,y) offset inside top-left corner of bbox for the label\n",
        "\n",
        "# ---------- read base imagery & georef ----------\n",
        "try:\n",
        "    with rasterio.open(INPUT_TIFF) as src:\n",
        "        base = src.read()                # (C,H,W)\n",
        "        transform = src.transform\n",
        "        crs = src.crs\n",
        "except rasterio.errors.RasterioIOError as e:\n",
        "    raise FileNotFoundError(f\"Could not read georeferenced image at {INPUT_TIFF}: {e}\")\n",
        "\n",
        "# Convert to HWC (OpenCV) and force 3 channels for visualization\n",
        "base = np.transpose(base, (1, 2, 0))     # (H,W,C)\n",
        "if base.shape[2] >= 3:\n",
        "    base_rgb = base[:, :, :3]\n",
        "else:\n",
        "    base_rgb = np.repeat(base, 3, axis=2)\n",
        "\n",
        "orig_h, orig_w = base_rgb.shape[:2]\n",
        "\n",
        "# ---------- pad canvas to tile grid (optional but handy) ----------\n",
        "H = math.ceil(orig_h / TILE) * TILE\n",
        "W = math.ceil(orig_w / TILE) * TILE\n",
        "pad_bottom = H - orig_h\n",
        "pad_right  = W - orig_w\n",
        "\n",
        "if pad_bottom > 0 or pad_right > 0:\n",
        "    pad_val = [int(base_rgb[-1,-1,0]), int(base_rgb[-1,-1,1]), int(base_rgb[-1,-1,2])]\n",
        "    canvas = cv2.copyMakeBorder(base_rgb, 0, pad_bottom, 0, pad_right,\n",
        "                                borderType=cv2.BORDER_CONSTANT, value=pad_val)\n",
        "else:\n",
        "    canvas = base_rgb.copy()\n",
        "\n",
        "# We will draw directly onto canvas (BGR for OpenCV convenience)\n",
        "canvas = canvas[:, :, ::-1]  # convert to BGR\n",
        "\n",
        "# ---------- iterate over npz tiles and draw ----------\n",
        "npz_files = sorted([f for f in os.listdir(PREDICTED_NPZ_DIR) if f.endswith(\"_pred.npz\")])\n",
        "if not npz_files:\n",
        "    print(f\"No *_pred.npz files found in {PREDICTED_NPZ_DIR}\")\n",
        "\n",
        "instances_drawn = 0\n",
        "\n",
        "for fname in npz_files:\n",
        "    fpath = os.path.join(PREDICTED_NPZ_DIR, fname)\n",
        "    try:\n",
        "        with np.load(fpath, allow_pickle=True) as data:\n",
        "            masks = data.get('masks', None)        # (N, th, tw) boolean/0-1\n",
        "            scores = data.get('scores', None)      # (N,)\n",
        "            classes = data.get('classes', None)    # (N,)\n",
        "            tile_origin_rc = data.get('tile_origin_rc', None)  # (r0, c0)\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping {fname}: cannot read npz ({e})\")\n",
        "        continue\n",
        "\n",
        "    if masks is None or masks.size == 0:\n",
        "        continue\n",
        "    if tile_origin_rc is None:\n",
        "        # Fallback: try to parse from filename like tile_rXXXX_cYYYY_pred.npz\n",
        "        # Adjust this parser to your actual naming if needed.\n",
        "        try:\n",
        "            base_name = os.path.splitext(fname)[0]\n",
        "            parts = base_name.split('_')\n",
        "            r0 = int([p for p in parts if p.startswith('r')][0][1:])\n",
        "            c0 = int([p for p in parts if p.startswith('c')][0][1:])\n",
        "        except Exception:\n",
        "            print(f\"Skipping {fname}: missing tile_origin_rc and filename not parseable.\")\n",
        "            continue\n",
        "    else:\n",
        "        r0, c0 = int(tile_origin_rc[0]), int(tile_origin_rc[1])\n",
        "\n",
        "    N, th, tw = masks.shape\n",
        "    # Bounds on canvas\n",
        "    r1 = r0 + th\n",
        "    c1 = c0 + tw\n",
        "    if r0 >= canvas.shape[0] or c0 >= canvas.shape[1]:\n",
        "        continue  # tile completely outside padded canvas\n",
        "    # Clip to canvas in case of edge/padding mismatch\n",
        "    rr0, cc0 = max(0, r0), max(0, c0)\n",
        "    rr1, cc1 = min(canvas.shape[0], r1), min(canvas.shape[1], c1)\n",
        "    if rr1 <= rr0 or cc1 <= cc0:\n",
        "        continue\n",
        "\n",
        "    # Region of interest on canvas (make a contiguous copy for drawing)\n",
        "    roi = canvas[rr0:rr1, cc0:cc1].copy()  # Make a copy here\n",
        "\n",
        "    # Matching region in tile coordinates\n",
        "    tr0 = rr0 - r0\n",
        "    tc0 = cc0 - c0\n",
        "    tr1 = th - (r1 - rr1)\n",
        "    tc1 = tw - (c1 - cc1)\n",
        "\n",
        "    # Draw each instance\n",
        "    for i in range(N):\n",
        "        m = masks[i, tr0:tr1, tc0:tc1].astype(np.uint8)  # (h,w) 0/1\n",
        "        if m.max() == 0:\n",
        "            continue\n",
        "        score = float(scores[i]) if scores is not None else None\n",
        "        class_id = int(classes[i]) if classes is not None else 0\n",
        "        # ---- CHANGED: pick color (fixed red or fallback per-class) ----\n",
        "        bgr = FIXED_COLOR_BGR if USE_FIXED_COLOR else color_from_class_id(class_id)\n",
        "\n",
        "        # ---- CHANGED: stronger fill alpha from config ----\n",
        "        alpha = ALPHA\n",
        "\n",
        "        # Overlay fill (mask tint)\n",
        "        colored = np.zeros_like(roi, dtype=np.uint8)\n",
        "        colored[:] = bgr\n",
        "        mask3 = np.repeat(m[:, :, None], 3, axis=2)  # (h,w,3)\n",
        "        roi[:] = np.where(mask3 == 1, (alpha * colored + (1 - alpha) * roi).astype(np.uint8), roi)\n",
        "\n",
        "        # Contour outline (optional; keeping it helps visually)\n",
        "        contours, _ = cv2.findContours((m * 255), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        cv2.drawContours(roi, contours, -1, bgr, 2, cv2.LINE_AA)\n",
        "\n",
        "        # ---- NEW: draw bounding box from the mask ----\n",
        "        if DRAW_BBOX:\n",
        "            ys, xs = np.where(m > 0)\n",
        "            if xs.size and ys.size:\n",
        "                x0, y0 = int(xs.min()), int(ys.min())\n",
        "                x1, y1 = int(xs.max()), int(ys.max())\n",
        "                cv2.rectangle(roi, (x0, y0), (x1, y1), bgr, 2, cv2.LINE_AA)\n",
        "\n",
        "        # ---- CHANGED: label at top-left of bbox (not centroid), percentage only ----\n",
        "        if score is not None:\n",
        "            pct = int(round(score * 100)) if 0.0 <= score <= 1.0 else int(round(score))\n",
        "            label = f\"{pct}%\"\n",
        "        else:\n",
        "            label = \"\"\n",
        "\n",
        "        if label:\n",
        "            # If we have a bbox, anchor to its top-left; otherwise, fallback to contour’s top-left\n",
        "            if DRAW_BBOX and xs.size and ys.size:\n",
        "                x0_lbl, y0_lbl = x0, y0\n",
        "            else:\n",
        "                # Fallback: use contour’s top-left from the largest contour (by area)\n",
        "                if contours:\n",
        "                    areas = [cv2.contourArea(c) for c in contours]\n",
        "                    k = int(np.argmax(areas))\n",
        "                    x0_lbl, y0_lbl, w_lbl, h_lbl = cv2.boundingRect(contours[k])\n",
        "                else:\n",
        "                    x0_lbl, y0_lbl = 0, 0\n",
        "\n",
        "            # Apply an offset so text is *inside* the region\n",
        "            ox, oy = LABEL_OFFSET\n",
        "            lx = max(0, min(x0_lbl + ox, roi.shape[1] - 1))\n",
        "            ly = max(12, min(y0_lbl + oy, roi.shape[0] - 1))\n",
        "            put_label(roi, label, (lx, ly), bg=(0, 0, 0), fg=(255, 255, 255))\n",
        "\n",
        "        instances_drawn += 1\n",
        "\n",
        "    # Copy the modified ROI back to the canvas\n",
        "    canvas[rr0:rr1, cc0:cc1] = roi\n",
        "\n",
        "\n",
        "# ---------- crop back and write geotiff ----------\n",
        "canvas = canvas[:, :, ::-1]  # back to RGB\n",
        "mosaic_vis_cropped = canvas[:orig_h, :orig_w, :]\n",
        "\n",
        "profile = {\n",
        "    \"driver\": \"GTiff\",\n",
        "    \"height\": orig_h,\n",
        "    \"width\":  orig_w,\n",
        "    \"count\":  3,\n",
        "    \"dtype\":  \"uint8\",\n",
        "    \"crs\":    crs,\n",
        "    \"transform\": transform,\n",
        "    \"compress\": \"lzw\",\n",
        "    \"photometric\": \"RGB\",\n",
        "    \"interleave\": \"pixel\",\n",
        "}\n",
        "\n",
        "with rasterio.open(OUTPUT_GEOTIFF, \"w\", **profile) as dst:\n",
        "    dst.write(np.transpose(mosaic_vis_cropped, (2, 0, 1)))\n",
        "    dst.colorinterp = (ColorInterp.red, ColorInterp.green, ColorInterp.blue)\n",
        "\n",
        "print(f\"Done. Drew {instances_drawn} instances from {len(npz_files)} tiles.\")\n",
        "print(f\"Wrote mosaic GeoTIFF with printed predictions to:\\n{OUTPUT_GEOTIFF}\")"
      ],
      "metadata": {
        "id": "I2FYQPwNmAU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the Image with the predicted instances"
      ],
      "metadata": {
        "id": "9WW4d-efx0II"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10592dd0"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Path to the generated mosaicked GeoTIFF\n",
        "# This variable is set in the previous cell (I2FYQPwNmAU3)\n",
        "image_to_display_path = OUTPUT_GEOTIFF\n",
        "\n",
        "# Read the image\n",
        "# Use -1 to load with original color depth and alpha channel if present\n",
        "image_to_display = cv2.imread(image_to_display_path, -1)\n",
        "\n",
        "if image_to_display is None:\n",
        "    print(f\"Error: Could not read image at {image_to_display_path}. Please check the file path.\")\n",
        "else:\n",
        "    # If it's a color image (3 or 4 channels), convert to BGR for cv2_imshow if needed\n",
        "    # cv2.imread reads in BGR by default for color images\n",
        "    # If it's a 4-channel image (like RGBA GeoTIFF), cv2_imshow handles it.\n",
        "    # If it's a single channel (grayscale), cv2_imshow also handles it.\n",
        "    # No explicit conversion needed for standard cases with cv2.imread\n",
        "\n",
        "    print(f\"Displaying image from: {image_to_display_path}\")\n",
        "    cv2_imshow(image_to_display)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}