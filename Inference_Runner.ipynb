{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNTBhTAU/I5rdzbaGLst86B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giolotar/Turkiye_detect/blob/main/Inference_Runner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Turkey Detect: Inference Runner**"
      ],
      "metadata": {
        "id": "mipGA6y2WN_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The following code loads a pretrained model with weights and configuration**\n",
        "\n",
        "The model was trained on the rubble instances of a single sat image of Antakya, Turkyie. Annotations were made in CVAT with one label \"Damage\" = \"Rubble\n",
        "The model weights and configuration are loaded and assembled into a predictor."
      ],
      "metadata": {
        "id": "qZtEQRjFWZGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The predictor then ingests a tif image, tiles it, runs predictions on the tiles, based on that predictions it does two things:\n",
        "\n",
        "\n",
        "\n",
        "1.   Generates a masks file .npz with the bounding boxes, coordinates and confidence grade for each prediction. the file which is then used to make a shapefile that is georeferenced to the injected tif\n",
        "2.   Generates a simple png image with the printed masks on it\n",
        "\n"
      ],
      "metadata": {
        "id": "5SqLf-81W0fV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SET-UP**"
      ],
      "metadata": {
        "id": "lfFCxhAFXrZ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44CaW_qRvXB2"
      },
      "outputs": [],
      "source": [
        "#Mount up the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Detectron2 Library\n",
        "!python -m pip install pyyaml==5.1\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "#Install geospatial libraries\n",
        "!pip install rasterio fiona shapely"
      ],
      "metadata": {
        "id": "HP6IyM8czlAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU Check\n",
        "\n",
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ],
      "metadata": {
        "id": "fpp663Az5KAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQ7HdUtkPWaI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os, json, cv2, random, math, re\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#import geospatial libraries\n",
        "from shapely.geometry import Polygon, mapping\n",
        "import fiona\n",
        "import rasterio\n",
        "from rasterio.enums import ColorInterp\n",
        "import glob\n",
        "\n",
        "# Detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# Detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load the Model and Config**\n",
        "\n",
        "Here we load a pretrained model configuration and weights"
      ],
      "metadata": {
        "id": "PPVu1FzuYGTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "from detectron2.config import get_cfg\n",
        "import os\n",
        "\n",
        "cfg_pretrained = get_cfg()\n",
        "\n",
        "saved_config_path = \"/content/drive/MyDrive/colabDL/TRF/model_10_Oct_TRF.yaml\"\n",
        "saved_weights_path = \"/content/drive/MyDrive/colabDL/TRF/model_best.pth\"\n",
        "\n",
        "# Load the configuration from the saved .yaml file using PyYAML\n",
        "with open(saved_config_path, 'r') as f:\n",
        "        # Use unsafe_load to handle the Python object tags in the YAML file\n",
        "        cfg_dict = yaml.unsafe_load(f) #unsafe load allows to load all yaml files\n",
        "\n",
        "    # Update the configuration with the loaded dictionary\n",
        "    # This is a safer way to merge than iterating over the dictionary\n",
        "cfg_pretrained.update(cfg_dict)\n",
        "\n",
        "\n",
        "# Set the path to the model weights\n",
        "cfg_pretrained.MODEL.WEIGHTS = saved_weights_path\n",
        "\n",
        "# Ensure the output directory is created (needed for the predictor)\n",
        "cfg_pretrained.OUTPUT_DIR = \"/content/sample_data\"\n",
        "os.makedirs(cfg_pretrained.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Configuration loaded and weights path set.\")"
      ],
      "metadata": {
        "id": "SYTihJmqtzhg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3250f138-7f96-4b0c-b83f-d78cba5b350b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration loaded and weights path set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Compile Predictor**"
      ],
      "metadata": {
        "id": "fV5KR3FjYvjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Threshold\n",
        "cfg_pretrained.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3\n",
        "\n",
        "# Assemble predictor\n",
        "predictor = DefaultPredictor(cfg_pretrained)\n",
        "\n",
        "print(\"DefaultPredictor initialized successfully with loaded configuration and weights.\")"
      ],
      "metadata": {
        "id": "6QZfxHSgYXJN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "b87b6e12-d042-4a2e-bb05-2ce362213999"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2602646395.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Assemble predictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDefaultPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_pretrained\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DefaultPredictor initialized successfully with loaded configuration and weights.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# cfg can be modified by model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASETS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/detectron2/modeling/meta_arch/build.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmeta_arch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMETA_ARCHITECTURE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMETA_ARCH_REGISTRY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_arch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0m_log_api_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"modeling.meta_arch.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmeta_arch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1367\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1353\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m                     )\n\u001b[0;32m-> 1355\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1356\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Predict on a Single Tile (Test)**\n",
        "\n",
        "Try to predict on a Test image / tile to check if the predictor works. This would require you have a splitted test database with tiles"
      ],
      "metadata": {
        "id": "-bzr4oopfkrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory containing the test tiles\n",
        "TEST_TILES_DIR = \"/content/drive/MyDrive/colabDL/tile1/test_row1to6_8\"\n",
        "\n",
        "# List all files in the directory\n",
        "tile_filenames = [f for f in os.listdir(TEST_TILES_DIR) if f.endswith('.tif') or f.endswith('.png') or f.endswith('.jpg')] # Add other image extensions if needed\n",
        "\n",
        "if not tile_filenames:\n",
        "    print(f\"No image files found in the directory: {TEST_TILES_DIR}\")\n",
        "else:\n",
        "    # Select a random filename\n",
        "    random_tile_filename = random.choice(tile_filenames)\n",
        "    random_tile_path = os.path.join(TEST_TILES_DIR, random_tile_filename)\n",
        "\n",
        "    print(f\"Loading random tile: {random_tile_filename}\")\n",
        "\n",
        "    # Read the random tile image\n",
        "    new_im = cv2.imread(random_tile_path)\n",
        "\n",
        "    if new_im is None:\n",
        "        print(f\"Error: Could not read image at {random_tile_path}. Please check the file path and ensure it's a valid image.\")\n",
        "    else:\n",
        "        # Ensure the image is in the correct format (e.g., 3 channels) if necessary for the predictor\n",
        "        if len(new_im.shape) == 2: # If grayscale\n",
        "            new_im = cv2.cvtColor(new_im, cv2.COLOR_GRAY2BGR)\n",
        "        elif new_im.shape[2] == 4: # If RGBA\n",
        "            new_im = new_im[:, :, :3] # Drop alpha channel\n",
        "\n",
        "\n",
        "        outputs  = predictor(new_im)\n",
        "\n",
        "v = Visualizer(new_im[:, :, ::-1], metadata=None)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "cv2_imshow(out.get_image()[:, :, ::-1]) # Convert back to RGB for displaying"
      ],
      "metadata": {
        "id": "krbzoGG0iKLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference**\n",
        "\n",
        "Then we run the predictor on an unseen Georeferenced TIF image, the image gets tiled, predictions are run on the tiles and exported in .npz as georeferenced polygons.\n",
        "Then they are turned into a shapefile"
      ],
      "metadata": {
        "id": "bex9MRnxWrwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Shapefile with predicted instances as Georeferenced Polygons"
      ],
      "metadata": {
        "id": "EygAnXpPW1e_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== USER PATHS ====\n",
        "INPUT_TIFF = \"/content/drive/MyDrive/colabDL/Turkiye/TR1/1_GEOTIFF.tif\" # Use the georeferenced TIFF\n",
        "OUT_DIR   = \"/content/drive/MyDrive/colabDL/Turkiye/TR1\"  # main output directory\n",
        "NPZ_OUT_DIR = os.path.join(OUT_DIR, \"npz_preds\") # subdirectory for npz files\n",
        "TILE = 1024\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "os.makedirs(NPZ_OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Read the georeferenced image and get georeferencing info\n",
        "try:\n",
        "    with rasterio.open(INPUT_TIFF) as src:\n",
        "        img = src.read()\n",
        "        # Rasterio reads bands first (C, H, W), convert to OpenCV format (H, W, C)\n",
        "        img = np.transpose(img, (1, 2, 0))\n",
        "        # Explicitly select the first 3 channels to handle potential alpha channels\n",
        "        if img.shape[2] == 4:\n",
        "            img = img[:, :, :3]\n",
        "        orig_h, orig_w = img.shape[:2]\n",
        "        transform = src.transform # Affine transform for georeferencing\n",
        "        crs = src.crs # Coordinate reference system\n",
        "\n",
        "except rasterio.errors.RasterioIOError as e:\n",
        "    raise FileNotFoundError(f\"Could not read georeferenced image at {INPUT_TIFF}: {e}\")\n",
        "\n",
        "# Pad to multiples of TILE so we don’t lose right/bottom edges\n",
        "H = math.ceil(orig_h / TILE) * TILE\n",
        "W = math.ceil(orig_w / TILE) * TILE\n",
        "pad_bottom = H - orig_h\n",
        "pad_right  = W - orig_w\n",
        "\n",
        "if pad_bottom or pad_right:\n",
        "    # Use the last pixel value for padding to avoid edge effects if possible,\n",
        "    # otherwise use black padding for color images.\n",
        "    if img.shape[2] == 3:\n",
        "        pad_val = [int(img[-1,-1,0]), int(img[-1,-1,1]), int(img[-1,-1,2])]\n",
        "    else:\n",
        "        pad_val = [0] * img.shape[2]\n",
        "    img = cv2.copyMakeBorder(\n",
        "        img, 0, pad_bottom, 0, pad_right,\n",
        "        borderType=cv2.BORDER_CONSTANT, value=pad_val\n",
        "    )\n",
        "\n",
        "rows = H // TILE\n",
        "cols = W // TILE\n",
        "\n",
        "tiles_written = 0\n",
        "dets_saved = 0\n",
        "\n",
        "for y in range(rows):\n",
        "    for x in range(cols):\n",
        "        r0 = y * TILE\n",
        "        c0 = x * TILE\n",
        "        tile = img[r0:r0+TILE, c0:c0+TILE]\n",
        "\n",
        "        # Calculate georeferenced origin of the tile (top-left corner)\n",
        "        geo_x0, geo_y0 = transform * (c0, r0)\n",
        "\n",
        "        # ---- Run inference on the tile\n",
        "        outputs = predictor(tile)\n",
        "        inst = outputs[\"instances\"].to(\"cpu\")\n",
        "\n",
        "        # ---- Extract raw predictions\n",
        "        boxes  = inst.pred_boxes.tensor.numpy() if inst.has(\"pred_boxes\") else np.zeros((0,4), dtype=np.float32)\n",
        "        scores = inst.scores.numpy()             if inst.has(\"scores\")     else np.zeros((0,), dtype=np.float32)\n",
        "        classes= inst.pred_classes.numpy()       if inst.has(\"pred_classes\") else np.zeros((0,), dtype=np.int32)\n",
        "        masks  = inst.pred_masks.numpy()         if inst.has(\"pred_masks\") else None  # (N, H, W) boolean\n",
        "\n",
        "        # ---- SAVE RAW PREDICTIONS (compressed)\n",
        "        # Include tile origin in pixel and georeferenced coordinates\n",
        "        npz_path = os.path.join(NPZ_OUT_DIR, f\"tile_{y}_{x}_pred.npz\")\n",
        "        np.savez_compressed(\n",
        "            npz_path,\n",
        "            boxes=boxes,\n",
        "            scores=scores,\n",
        "            classes=classes,\n",
        "            masks=masks,                 # None is allowed; np.load(..., allow_pickle=True) will handle it\n",
        "            tile_row=y,\n",
        "            tile_col=x,\n",
        "            tile_origin_rc=np.array([r0, c0], dtype=np.int32), # Pixel origin (row, col)\n",
        "            tile_origin_geo=np.array([geo_x0, geo_y0], dtype=np.float64), # Georeferenced origin (x, y)\n",
        "            tile_size=TILE,\n",
        "            padded_h=H,\n",
        "            padded_w=W,\n",
        "            orig_h=orig_h,\n",
        "            orig_w=orig_w,\n",
        "            pad_bottom=pad_bottom,\n",
        "            pad_right=pad_right\n",
        "        )\n",
        "        dets_saved += len(boxes)\n",
        "\n",
        "print(f\"Done. Wrote {tiles_written} visualized tiles to {OUT_DIR}\")\n",
        "print(f\"Saved predictions for {rows*cols} tiles ({dets_saved} detections total) as .npz files to {NPZ_OUT_DIR}\")"
      ],
      "metadata": {
        "id": "cHUiBpUR5Rr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert from the npz to shp retaining geographic coordinates"
      ],
      "metadata": {
        "id": "xdXEnh2vUGjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory containing the predicted tile .npz files\n",
        "PREDICTED_NPZ_DIR = \"/content/drive/MyDrive/colabDL/Turkiye/TR1/npz_preds\" # Assuming npz files are in a subdirectory\n",
        "\n",
        "OUTPUT_VECTOR_PATH = \"/content/drive/MyDrive/colabDL/Turkiye/TR1/Rubble_1.gpkg\"\n",
        "\n",
        "ORIGINAL_GEOREFERENCED_IMAGE_PATH = \"/content/drive/MyDrive/colabDL/Turkiye/TR1/1_GEOTIFF.tif\" # Example path, replace with your actual georeferenced image path\n",
        "\n",
        "# --- Function to get georeferencing information ---\n",
        "def get_georeferencing_info(image_path):\n",
        "    \"\"\"Reads georeferencing information (transform and CRS) from a georeferenced image.\"\"\"\n",
        "    try:\n",
        "        with rasterio.open(image_path) as src:\n",
        "            return src.transform, src.crs\n",
        "    except rasterio.errors.RasterioIOError as e:\n",
        "        print(f\"Error reading georeferencing info from {image_path}: {e}\")\n",
        "        print(\"Assuming pixel coordinates. The output vector file will NOT be georeferenced.\")\n",
        "        return None, None\n",
        "\n",
        "# Get georeferencing info from the original image\n",
        "transform, crs = get_georeferencing_info(ORIGINAL_GEOREFERENCED_IMAGE_PATH)\n",
        "\n",
        "# --- Define the schema for the vector file ---\n",
        "\n",
        "schema = {\n",
        "    'geometry': 'Polygon',\n",
        "    'properties': {'score': 'float', 'class_id': 'int'},\n",
        "}\n",
        "\n",
        "# --- Create the vector file (Geopackage) ---\n",
        "driver = 'GPKG'\n",
        "\n",
        "with fiona.open(\n",
        "    OUTPUT_VECTOR_PATH,\n",
        "    'w',\n",
        "    driver,\n",
        "    schema,\n",
        "    crs=crs # Use the obtained CRS, or None if not available\n",
        ") as collection:\n",
        "    # List all .npz files in the directory\n",
        "    npz_filenames = [f for f in os.listdir(PREDICTED_NPZ_DIR) if f.endswith('_pred.npz')]\n",
        "\n",
        "    if not npz_filenames:\n",
        "        print(\"No predicted .npz files found in the directory.\")\n",
        "    else:\n",
        "        # Iterate through each .npz file\n",
        "        for filename in npz_filenames:\n",
        "            npz_path = os.path.join(PREDICTED_NPZ_DIR, filename)\n",
        "            with np.load(npz_path, allow_pickle=True) as data:\n",
        "                masks = data['masks']\n",
        "                scores = data['scores']\n",
        "                classes = data['classes']\n",
        "                tile_origin_rc = data['tile_origin_rc'] # Pixel origin (r0, c0)\n",
        "\n",
        "\n",
        "                if masks is not None and masks.shape[0] > 0:\n",
        "                    # Process each instance mask within the tile\n",
        "                    for i in range(masks.shape[0]):\n",
        "                        instance_mask = masks[i]\n",
        "                        score = scores[i]\n",
        "                        class_id = classes[i]\n",
        "\n",
        "\n",
        "                        mask_uint8 = instance_mask.astype(np.uint8) * 255\n",
        "                        # Use cv2.RETR_TREE and cv2.CHAIN_APPROX_NONE for more detailed contours if needed,\n",
        "                        # but SIMPLE is usually sufficient for polygons.\n",
        "                        contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                        # Convert contours to polygons and transform coordinates\n",
        "                        for contour in contours:\n",
        "\n",
        "                            contour_points_tile = contour.squeeze().tolist()\n",
        "\n",
        "                            if not isinstance(contour_points_tile, list):\n",
        "                                # Handle cases where contour.squeeze() results in a single point\n",
        "                                contour_points_tile = [contour_points_tile]\n",
        "                            elif not all(isinstance(p, list) for p in contour_points_tile):\n",
        "                                # Handle cases where contour.squeeze() results in a flat list of coords\n",
        "                                contour_points_tile = [contour_points_tile]\n",
        "\n",
        "\n",
        "                            if len(contour_points_tile) < 3:\n",
        "                                continue # Skip if not enough points to form a polygon\n",
        "\n",
        "                            # Convert tile pixel coordinates to padded image pixel coordinates\n",
        "                            # Tile origin is (row, col), contour points are (col, row)\n",
        "                            contour_points_padded = [(p[0] + tile_origin_rc[1], p[1] + tile_origin_rc[0]) for p in contour_points_tile]\n",
        "\n",
        "                            # Convert padded image pixel coordinates to geographic coordinates using the original image's transform\n",
        "                            if transform:\n",
        "                                # Apply the affine transform to each point\n",
        "                                # transform * (col, row) gives (x, y) georeferenced coordinates\n",
        "                                contour_points_geo = [transform * (p[0], p[1]) for p in contour_points_padded]\n",
        "                                polygon = Polygon(contour_points_geo)\n",
        "                            else:\n",
        "                                # If no transform, use padded pixel coordinates for the polygon\n",
        "                                polygon = Polygon(contour_points_padded)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                                # Add the polygon and its properties to the vector file\n",
        "                            if not polygon.is_empty and polygon.exterior: # Ensure polygon is valid and not empty\n",
        "                                # Cast score to a standard float type to potentially avoid Fiona warning\n",
        "                                collection.write({\n",
        "                                    'geometry': mapping(polygon),\n",
        "                                    'properties': {'score': float(score), 'class_id': int(class_id)},\n",
        "                                })\n",
        "\n",
        "print(f\"Vector file (Geopackage) saved to {OUTPUT_VECTOR_PATH}\")"
      ],
      "metadata": {
        "id": "9iOIBvZq9XBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Produce a .TIF image mosaic with the predictions and bounding boxes printed on the image."
      ],
      "metadata": {
        "id": "SCqAzQ2FhVTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#use npz to create a geotiff\n",
        "\n",
        "# ==== USER PATHS ====\n",
        "INPUT_TIFF = \"/content/drive/MyDrive/colabDL/Turkiye/TR1/1_GEOTIFF.tif\"  # original georeferenced image\n",
        "OUT_DIR    = \"/content/drive/MyDrive/colabDL/Turkiye/TR1/Rubble_2_tif\"   # output directory\n",
        "OUTPUT_GEOTIFF = os.path.join(OUT_DIR, \"Rubble_1_predictions_vis.tif\")   # final mosaic GeoTIFF\n",
        "PREDICTED_NPZ_DIR = \"/content/drive/MyDrive/colabDL/Turkiye/TR1/npz_preds\"  # folder with *_pred.npz\n",
        "TILE = 1024\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def color_from_class_id(class_id: int) -> tuple:\n",
        "\n",
        "    rng = np.random.RandomState(class_id * 1337 + 42)\n",
        "    return tuple(int(x) for x in rng.choice(256, size=3))  # BGR\n",
        "\n",
        "def put_label(img, text, pt, bg=(0,0,0), fg=(255,255,255)):\n",
        "\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    scale = 0.5\n",
        "    thickness = 1\n",
        "    (tw, th), baseline = cv2.getTextSize(text, font, scale, thickness)\n",
        "    x, y = pt\n",
        "    cv2.rectangle(img, (x, y - th - baseline), (x + tw, y + baseline), bg, -1, cv2.LINE_AA)\n",
        "    cv2.putText(img, text, (x, y), font, scale, fg, thickness, cv2.LINE_AA)\n",
        "\n",
        "# ---------- visualization config (ADD THIS) ----------\n",
        "USE_FIXED_COLOR = True                # force one color for all instances\n",
        "FIXED_COLOR_BGR = (0, 0, 255)         # red in BGR\n",
        "ALPHA = 0.45                          # mask fill opacity\n",
        "DRAW_BBOX = True                      # draw bounding boxes\n",
        "LABEL_OFFSET = (2, 12)                # (x,y) offset inside top-left corner of bbox for the label\n",
        "\n",
        "# ---------- read base imagery & georef ----------\n",
        "try:\n",
        "    with rasterio.open(INPUT_TIFF) as src:\n",
        "        base = src.read()                # (C,H,W)\n",
        "        transform = src.transform\n",
        "        crs = src.crs\n",
        "except rasterio.errors.RasterioIOError as e:\n",
        "    raise FileNotFoundError(f\"Could not read georeferenced image at {INPUT_TIFF}: {e}\")\n",
        "\n",
        "# Convert to HWC (OpenCV) and force 3 channels for visualization\n",
        "base = np.transpose(base, (1, 2, 0))     # (H,W,C)\n",
        "if base.shape[2] >= 3:\n",
        "    base_rgb = base[:, :, :3]\n",
        "else:\n",
        "    base_rgb = np.repeat(base, 3, axis=2)\n",
        "\n",
        "orig_h, orig_w = base_rgb.shape[:2]\n",
        "\n",
        "# ---------- pad canvas to tile grid (optional but handy) ----------\n",
        "H = math.ceil(orig_h / TILE) * TILE\n",
        "W = math.ceil(orig_w / TILE) * TILE\n",
        "pad_bottom = H - orig_h\n",
        "pad_right  = W - orig_w\n",
        "\n",
        "if pad_bottom > 0 or pad_right > 0:\n",
        "    pad_val = [int(base_rgb[-1,-1,0]), int(base_rgb[-1,-1,1]), int(base_rgb[-1,-1,2])]\n",
        "    canvas = cv2.copyMakeBorder(base_rgb, 0, pad_bottom, 0, pad_right,\n",
        "                                borderType=cv2.BORDER_CONSTANT, value=pad_val)\n",
        "else:\n",
        "    canvas = base_rgb.copy()\n",
        "\n",
        "# We will draw directly onto canvas (BGR for OpenCV convenience)\n",
        "canvas = canvas[:, :, ::-1]  # convert to BGR\n",
        "\n",
        "# ---------- iterate over npz tiles and draw ----------\n",
        "npz_files = sorted([f for f in os.listdir(PREDICTED_NPZ_DIR) if f.endswith(\"_pred.npz\")])\n",
        "if not npz_files:\n",
        "    print(f\"No *_pred.npz files found in {PREDICTED_NPZ_DIR}\")\n",
        "\n",
        "instances_drawn = 0\n",
        "\n",
        "for fname in npz_files:\n",
        "    fpath = os.path.join(PREDICTED_NPZ_DIR, fname)\n",
        "    try:\n",
        "        with np.load(fpath, allow_pickle=True) as data:\n",
        "            masks = data.get('masks', None)        # (N, th, tw) boolean/0-1\n",
        "            scores = data.get('scores', None)      # (N,)\n",
        "            classes = data.get('classes', None)    # (N,)\n",
        "            tile_origin_rc = data.get('tile_origin_rc', None)  # (r0, c0)\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping {fname}: cannot read npz ({e})\")\n",
        "        continue\n",
        "\n",
        "    if masks is None or masks.size == 0:\n",
        "        continue\n",
        "    if tile_origin_rc is None:\n",
        "\n",
        "        try:\n",
        "            base_name = os.path.splitext(fname)[0]\n",
        "            parts = base_name.split('_')\n",
        "            r0 = int([p for p in parts if p.startswith('r')][0][1:])\n",
        "            c0 = int([p for p in parts if p.startswith('c')][0][1:])\n",
        "        except Exception:\n",
        "            print(f\"Skipping {fname}: missing tile_origin_rc and filename not parseable.\")\n",
        "            continue\n",
        "    else:\n",
        "        r0, c0 = int(tile_origin_rc[0]), int(tile_origin_rc[1])\n",
        "\n",
        "    N, th, tw = masks.shape\n",
        "    # Bounds on canvas\n",
        "    r1 = r0 + th\n",
        "    c1 = c0 + tw\n",
        "    if r0 >= canvas.shape[0] or c0 >= canvas.shape[1]:\n",
        "        continue  # tile completely outside padded canvas\n",
        "    # Clip to canvas in case of edge/padding mismatch\n",
        "    rr0, cc0 = max(0, r0), max(0, c0)\n",
        "    rr1, cc1 = min(canvas.shape[0], r1), min(canvas.shape[1], c1)\n",
        "    if rr1 <= rr0 or cc1 <= cc0:\n",
        "        continue\n",
        "\n",
        "    # Region of interest on canvas (make a contiguous copy for drawing)\n",
        "    roi = canvas[rr0:rr1, cc0:cc1].copy()  # Make a copy here\n",
        "\n",
        "    # Matching region in tile coordinates\n",
        "    tr0 = rr0 - r0\n",
        "    tc0 = cc0 - c0\n",
        "    tr1 = th - (r1 - rr1)\n",
        "    tc1 = tw - (c1 - cc1)\n",
        "\n",
        "    # Draw each instance\n",
        "    for i in range(N):\n",
        "        m = masks[i, tr0:tr1, tc0:tc1].astype(np.uint8)  # (h,w) 0/1\n",
        "        if m.max() == 0:\n",
        "            continue\n",
        "        score = float(scores[i]) if scores is not None else None\n",
        "        class_id = int(classes[i]) if classes is not None else 0\n",
        "\n",
        "        bgr = FIXED_COLOR_BGR if USE_FIXED_COLOR else color_from_class_id(class_id)\n",
        "\n",
        "        alpha = ALPHA\n",
        "\n",
        "        # Overlay fill (mask tint)\n",
        "        colored = np.zeros_like(roi, dtype=np.uint8)\n",
        "        colored[:] = bgr\n",
        "        mask3 = np.repeat(m[:, :, None], 3, axis=2)  # (h,w,3)\n",
        "        roi[:] = np.where(mask3 == 1, (alpha * colored + (1 - alpha) * roi).astype(np.uint8), roi)\n",
        "\n",
        "        # Contour outline (optional; keeping it helps visually)\n",
        "        contours, _ = cv2.findContours((m * 255), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        cv2.drawContours(roi, contours, -1, bgr, 2, cv2.LINE_AA)\n",
        "\n",
        "        # ---- draw bounding box from the mask ----\n",
        "        if DRAW_BBOX:\n",
        "            ys, xs = np.where(m > 0)\n",
        "            if xs.size and ys.size:\n",
        "                x0, y0 = int(xs.min()), int(ys.min())\n",
        "                x1, y1 = int(xs.max()), int(ys.max())\n",
        "                cv2.rectangle(roi, (x0, y0), (x1, y1), bgr, 2, cv2.LINE_AA)\n",
        "\n",
        "        # ---- label at top-left of bbox ----\n",
        "        if score is not None:\n",
        "            pct = int(round(score * 100)) if 0.0 <= score <= 1.0 else int(round(score))\n",
        "            label = f\"{pct}%\"\n",
        "        else:\n",
        "            label = \"\"\n",
        "\n",
        "        if label:\n",
        "            # If we have a bbox, anchor to its top-left; otherwise, fallback to contour’s top-left\n",
        "            if DRAW_BBOX and xs.size and ys.size:\n",
        "                x0_lbl, y0_lbl = x0, y0\n",
        "            else:\n",
        "                # Fallback: use contour’s top-left from the largest contour (by area)\n",
        "                if contours:\n",
        "                    areas = [cv2.contourArea(c) for c in contours]\n",
        "                    k = int(np.argmax(areas))\n",
        "                    x0_lbl, y0_lbl, w_lbl, h_lbl = cv2.boundingRect(contours[k])\n",
        "                else:\n",
        "                    x0_lbl, y0_lbl = 0, 0\n",
        "\n",
        "            # Apply an offset so text is *inside* the region\n",
        "            ox, oy = LABEL_OFFSET\n",
        "            lx = max(0, min(x0_lbl + ox, roi.shape[1] - 1))\n",
        "            ly = max(12, min(y0_lbl + oy, roi.shape[0] - 1))\n",
        "            put_label(roi, label, (lx, ly), bg=(0, 0, 0), fg=(255, 255, 255))\n",
        "\n",
        "        instances_drawn += 1\n",
        "\n",
        "    canvas[rr0:rr1, cc0:cc1] = roi\n",
        "\n",
        "\n",
        "# ---------- crop back and write geotiff ----------\n",
        "canvas = canvas[:, :, ::-1]  # back to RGB\n",
        "mosaic_vis_cropped = canvas[:orig_h, :orig_w, :]\n",
        "\n",
        "profile = {\n",
        "    \"driver\": \"GTiff\",\n",
        "    \"height\": orig_h,\n",
        "    \"width\":  orig_w,\n",
        "    \"count\":  3,\n",
        "    \"dtype\":  \"uint8\",\n",
        "    \"crs\":    crs,\n",
        "    \"transform\": transform,\n",
        "    \"compress\": \"lzw\",\n",
        "    \"photometric\": \"RGB\",\n",
        "    \"interleave\": \"pixel\",\n",
        "}\n",
        "\n",
        "with rasterio.open(OUTPUT_GEOTIFF, \"w\", **profile) as dst:\n",
        "    dst.write(np.transpose(mosaic_vis_cropped, (2, 0, 1)))\n",
        "    dst.colorinterp = (ColorInterp.red, ColorInterp.green, ColorInterp.blue)\n",
        "\n",
        "print(f\"Done. Drew {instances_drawn} instances from {len(npz_files)} tiles.\")\n",
        "print(f\"Wrote mosaic GeoTIFF with printed predictions to:\\n{OUTPUT_GEOTIFF}\")"
      ],
      "metadata": {
        "id": "I2FYQPwNmAU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the Image with the predicted instances"
      ],
      "metadata": {
        "id": "9WW4d-efx0II"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10592dd0"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "image_to_display_path = OUTPUT_GEOTIFF\n",
        "\n",
        "image_to_display = cv2.imread(image_to_display_path, -1)\n",
        "\n",
        "if image_to_display is None:\n",
        "    print(f\"Error: Could not read image at {image_to_display_path}. Please check the file path.\")\n",
        "else:\n",
        "\n",
        "    print(f\"Displaying image from: {image_to_display_path}\")\n",
        "    cv2_imshow(image_to_display)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}