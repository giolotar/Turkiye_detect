{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPU56LCm4zc0qH44WU2BvBt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giolotar/Turkiye_detect/blob/main/Inference_Runner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **The following code loads a pretrained model with weights and configuration**\n",
        "\n",
        "The model was trained on the rubble instances of a single sat image of Antakya, Turkyie. Annotations were made in CVAT with one label \"Damage\" = \"Rubble\n",
        "The model weights and configuration are loaded and assembled into a predictor."
      ],
      "metadata": {
        "id": "qZtEQRjFWZGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The predictor then ingests a tif image, tiles it, runs predictions on the tiles, based on that predictions it does two things:\n",
        "\n",
        "\n",
        "\n",
        "1.   Generates a masks file .npz with the bounding boxes, coordinates and confidence grade for each prediction. the file which is then used to make a shapefile that is georeferenced to the injected tif\n",
        "2.   Generates a simple png image with the printed masks on it\n",
        "\n"
      ],
      "metadata": {
        "id": "5SqLf-81W0fV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SET-UP**"
      ],
      "metadata": {
        "id": "lfFCxhAFXrZ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "44CaW_qRvXB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad98f6c-206f-4964-eeb1-05b206d9c1cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Mount up the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Detectron2 Library\n",
        "!python -m pip install pyyaml==5.1\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "metadata": {
        "id": "HP6IyM8czlAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86feb36c-631a-4dcb-d778-67705c0b951a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.1\n",
            "  Using cached PyYAML-5.1.tar.gz (274 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-95usekls\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-95usekls\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit a1ce2f956a1d2212ad672e3c47d53405c2fe4312\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (3.10.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (2.0.10)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (3.1.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (2.19.0)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (0.1.9)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (1.3.2)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (25.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (25.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (3.2.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from black->detectron2==0.6) (8.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from black->detectron2==0.6) (1.1.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from black->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.12/dist-packages (from black->detectron2==0.6) (4.4.0)\n",
            "Requirement already satisfied: pytokens>=0.1.10 in /usr/local/lib/python3.12/dist-packages (from black->detectron2==0.6) (0.1.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (2.9.0.post0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (1.75.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (3.9)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard->detectron2==0.6) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU Check\n",
        "\n",
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ],
      "metadata": {
        "id": "fpp663Az5KAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c1c71e-b7ab-4574-9b66-6c52a05807a9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "torch:  2.8 ; cuda:  cu126\n",
            "detectron2: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pQ7HdUtkPWaI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# Detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mywty7XQYHIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load the Model and Config**"
      ],
      "metadata": {
        "id": "PPVu1FzuYGTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cfg_pretrained = get_cfg()\n",
        "\n",
        "saved_config_path = \"/content/drive/MyDrive/colabDL/turkey_OGrun.yaml\"\n",
        "saved_weights_path = \"/content/drive/MyDrive/colabDL/tile1/model_final_cfg2.pth\"\n",
        "\n",
        "# Load the configuration directly from your saved .yaml file\n",
        "try:\n",
        "    cfg_pretrained.merge_from_file(saved_config_path)\n",
        "except KeyError as e:\n",
        "    print(f\"Error loading configuration from {saved_config_path}: {e}\")\n",
        "    raise\n",
        "\n",
        "# Set the path to the model weights\n",
        "cfg_pretrained.MODEL.WEIGHTS = saved_weights_path\n",
        "\n",
        "# Ensure the output directory is created (needed for the predictor)\n",
        "cfg_pretrained.OUTPUT_DIR = \"/content/sample_data\"\n",
        "os.makedirs(cfg_pretrained.OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "SYTihJmqtzhg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72c17a7b-b6ea-42e7-80fe-31695e095fb7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.config:Loading config /content/drive/MyDrive/colabDL/turkey_OGrun.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Compile Predictor**"
      ],
      "metadata": {
        "id": "fV5KR3FjYvjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Threshold\n",
        "cfg_pretrained.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3\n",
        "\n",
        "# Assemble predictor\n",
        "predictor = DefaultPredictor(cfg_pretrained)\n",
        "\n",
        "print(\"DefaultPredictor initialized successfully with loaded configuration and weights.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QZfxHSgYXJN",
        "outputId": "47d3e979-197f-42a7-dda6-2c051e2fcb0f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10/05 13:28:03 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /content/drive/MyDrive/colabDL/tile1/model_final_cfg2.pth ...\n",
            "DefaultPredictor initialized successfully with loaded configuration and weights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to predict normally on an image / tile see if the predictor works"
      ],
      "metadata": {
        "id": "-bzr4oopfkrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_im = cv2.imread(\"/content/drive/MyDrive/colabDL/tile1/test_row1to6_8/tile_y4095_x7371_row5_col9.tif\")\n",
        "outputs  = predictor(new_im)\n",
        "\n",
        "# We can use `Visualizer` to draw the predictions on the image.\n",
        "\n",
        "#!!! NEED TO EXPLORE WITH VISUALIZER OPTIONS MORE APPEALING MASKS REPRESENTATIONS\n",
        "v = Visualizer(new_im[:, :, ::-1], metadata=None)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "krbzoGG0iKLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we run the predictor on an unseen Georef image, the image gets tiled, predictions are run on the tiles and exported in .npz as georeferenced polygons.\n",
        "Then they are turned into a shapefile"
      ],
      "metadata": {
        "id": "rsaD3p1ciMkq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65cee5f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f27a33b-2b68-4dbd-cad1-c9efcec93c43"
      },
      "source": [
        "!pip install rasterio fiona shapely"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.12/dist-packages (1.4.3)\n",
            "Requirement already satisfied: fiona in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.12/dist-packages (2.1.2)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2025.8.3)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.3.0)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.0.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.12/dist-packages (from rasterio) (1.1.1.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tile_tiff_save_preds.py\n",
        "import os\n",
        "import math\n",
        "import cv2\n",
        "import numpy as np\n",
        "import rasterio # Import rasterio for georeferenced image handling\n",
        "\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog  # needed for Visualizer\n",
        "\n",
        "# ==== USER PATHS ====\n",
        "INPUT_TIFF = \"/content/drive/MyDrive/colabDL/TURCHIA4.10/3GEOTIFF410/3_GEOTIFF.tif\" # Use the georeferenced TIFF\n",
        "OUT_DIR   = \"/content/drive/MyDrive/colabDL/TURCHIA4.10/3GEOTIFF410\"  # main output directory\n",
        "NPZ_OUT_DIR = os.path.join(OUT_DIR, \"npz_preds\") # subdirectory for npz files\n",
        "TILE = 1024\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "os.makedirs(NPZ_OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Read the georeferenced image and get georeferencing info\n",
        "try:\n",
        "    with rasterio.open(INPUT_TIFF) as src:\n",
        "        img = src.read()\n",
        "        # Rasterio reads bands first (C, H, W), convert to OpenCV format (H, W, C)\n",
        "        img = np.transpose(img, (1, 2, 0))\n",
        "        # Explicitly select the first 3 channels to handle potential alpha channels\n",
        "        if img.shape[2] == 4:\n",
        "            img = img[:, :, :3]\n",
        "        orig_h, orig_w = img.shape[:2]\n",
        "        transform = src.transform # Affine transform for georeferencing\n",
        "        crs = src.crs # Coordinate reference system\n",
        "\n",
        "except rasterio.errors.RasterioIOError as e:\n",
        "    raise FileNotFoundError(f\"Could not read georeferenced image at {INPUT_TIFF}: {e}\")\n",
        "\n",
        "# Pad to multiples of TILE so we don’t lose right/bottom edges\n",
        "H = math.ceil(orig_h / TILE) * TILE\n",
        "W = math.ceil(orig_w / TILE) * TILE\n",
        "pad_bottom = H - orig_h\n",
        "pad_right  = W - orig_w\n",
        "\n",
        "if pad_bottom or pad_right:\n",
        "    # Use the last pixel value for padding to avoid edge effects if possible,\n",
        "    # otherwise use black padding for color images.\n",
        "    if img.shape[2] == 3:\n",
        "        pad_val = [int(img[-1,-1,0]), int(img[-1,-1,1]), int(img[-1,-1,2])]\n",
        "    else:\n",
        "        pad_val = [0] * img.shape[2]\n",
        "    img = cv2.copyMakeBorder(\n",
        "        img, 0, pad_bottom, 0, pad_right,\n",
        "        borderType=cv2.BORDER_CONSTANT, value=pad_val\n",
        "    )\n",
        "\n",
        "rows = H // TILE\n",
        "cols = W // TILE\n",
        "\n",
        "tiles_written = 0\n",
        "dets_saved = 0\n",
        "\n",
        "for y in range(rows):\n",
        "    for x in range(cols):\n",
        "        r0 = y * TILE\n",
        "        c0 = x * TILE\n",
        "        tile = img[r0:r0+TILE, c0:c0+TILE]\n",
        "\n",
        "        # Calculate georeferenced origin of the tile (top-left corner)\n",
        "        geo_x0, geo_y0 = transform * (c0, r0)\n",
        "\n",
        "        # ---- Run inference on the tile\n",
        "        outputs = predictor(tile)\n",
        "        inst = outputs[\"instances\"].to(\"cpu\")\n",
        "\n",
        "        # ---- Extract raw predictions\n",
        "        boxes  = inst.pred_boxes.tensor.numpy() if inst.has(\"pred_boxes\") else np.zeros((0,4), dtype=np.float32)\n",
        "        scores = inst.scores.numpy()             if inst.has(\"scores\")     else np.zeros((0,), dtype=np.float32)\n",
        "        classes= inst.pred_classes.numpy()       if inst.has(\"pred_classes\") else np.zeros((0,), dtype=np.int32)\n",
        "        masks  = inst.pred_masks.numpy()         if inst.has(\"pred_masks\") else None  # (N, H, W) boolean\n",
        "\n",
        "        # ---- SAVE RAW PREDICTIONS (compressed)\n",
        "        # Include tile origin in pixel and georeferenced coordinates\n",
        "        npz_path = os.path.join(NPZ_OUT_DIR, f\"tile_{y}_{x}_pred.npz\")\n",
        "        np.savez_compressed(\n",
        "            npz_path,\n",
        "            boxes=boxes,\n",
        "            scores=scores,\n",
        "            classes=classes,\n",
        "            masks=masks,                 # None is allowed; np.load(..., allow_pickle=True) will handle it\n",
        "            tile_row=y,\n",
        "            tile_col=x,\n",
        "            tile_origin_rc=np.array([r0, c0], dtype=np.int32), # Pixel origin (row, col)\n",
        "            tile_origin_geo=np.array([geo_x0, geo_y0], dtype=np.float64), # Georeferenced origin (x, y)\n",
        "            tile_size=TILE,\n",
        "            padded_h=H,\n",
        "            padded_w=W,\n",
        "            orig_h=orig_h,\n",
        "            orig_w=orig_w,\n",
        "            pad_bottom=pad_bottom,\n",
        "            pad_right=pad_right\n",
        "        )\n",
        "        dets_saved += len(boxes)\n",
        "\n",
        "print(f\"Done. Wrote {tiles_written} visualized tiles to {OUT_DIR}\")\n",
        "print(f\"Saved predictions for {rows*cols} tiles ({dets_saved} detections total) as .npz files to {NPZ_OUT_DIR}\")"
      ],
      "metadata": {
        "id": "cHUiBpUR5Rr3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8c6786e-5d2a-4925-f582-97a4d5f65d1f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4322.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. Wrote 0 visualized tiles to /content/drive/MyDrive/colabDL/TURCHIA4.10/3GEOTIFF410\n",
            "Saved predictions for 110 tiles (103 detections total) as .npz files to /content/drive/MyDrive/colabDL/TURCHIA4.10/3GEOTIFF410/npz_preds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "convert from the npz to shp retaining geographic coordinates"
      ],
      "metadata": {
        "id": "xdXEnh2vUGjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "import rasterio\n",
        "from shapely.geometry import Polygon, mapping\n",
        "import fiona"
      ],
      "metadata": {
        "id": "MszJ1WCOUK-J"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory containing the predicted tile .npz files\n",
        "PREDICTED_NPZ_DIR = \"/content/drive/MyDrive/colabDL/TURCHIA4.10/3GEOTIFF410/npz_preds\" # Assuming npz files are in a subdirectory\n",
        "\n",
        "# Output shapefile/geopackage path\n",
        "# Changed to .gpkg for geopackage, which is preferred\n",
        "OUTPUT_VECTOR_PATH = \"/content/drive/MyDrive/colabDL/TURCHIA4.10/3GEOTIFF410/rubble_predictions_4.gpkg\"\n",
        "\n",
        "# Path to the original georeferenced image (GeoTIFF or similar)\n",
        "\n",
        "# This is necessary to get the coordinate system and transform information.\n",
        "ORIGINAL_GEOREFERENCED_IMAGE_PATH = \"/content/drive/MyDrive/colabDL/TURCHIA4.10/3GEOTIFF410/3_GEOTIFF.tif\" # Example path, replace with your actual georeferenced image path\n",
        "\n",
        "# --- Function to get georeferencing information ---\n",
        "def get_georeferencing_info(image_path):\n",
        "    \"\"\"Reads georeferencing information (transform and CRS) from a georeferenced image.\"\"\"\n",
        "    try:\n",
        "        with rasterio.open(image_path) as src:\n",
        "            return src.transform, src.crs\n",
        "    except rasterio.errors.RasterioIOError as e:\n",
        "        print(f\"Error reading georeferencing info from {image_path}: {e}\")\n",
        "        print(\"Assuming pixel coordinates. The output vector file will NOT be georeferenced.\")\n",
        "        return None, None\n",
        "\n",
        "# Get georeferencing info from the original image\n",
        "transform, crs = get_georeferencing_info(ORIGINAL_GEOREFERENCED_IMAGE_PATH)\n",
        "\n",
        "# --- Define the schema for the vector file ---\n",
        "# This defines the attributes (columns) for each feature (polygon) in the vector file.\n",
        "# We'll include score and class_id from the predictions.\n",
        "schema = {\n",
        "    'geometry': 'Polygon',\n",
        "    'properties': {'score': 'float', 'class_id': 'int'},\n",
        "}\n",
        "\n",
        "# --- Create the vector file (Geopackage) ---\n",
        "# Determine the driver based on the output file extension\n",
        "# Changed driver to GPKG for Geopackage\n",
        "driver = 'GPKG'\n",
        "\n",
        "# Open the vector file in write mode\n",
        "# If a CRS was obtained, use it. Otherwise, the vector file will have no defined CRS.\n",
        "with fiona.open(\n",
        "    OUTPUT_VECTOR_PATH,\n",
        "    'w',\n",
        "    driver,\n",
        "    schema,\n",
        "    crs=crs # Use the obtained CRS, or None if not available\n",
        ") as collection:\n",
        "    # List all .npz files in the directory\n",
        "    npz_filenames = [f for f in os.listdir(PREDICTED_NPZ_DIR) if f.endswith('_pred.npz')]\n",
        "\n",
        "    if not npz_filenames:\n",
        "        print(\"No predicted .npz files found in the directory.\")\n",
        "    else:\n",
        "        # Iterate through each .npz file\n",
        "        for filename in npz_filenames:\n",
        "            npz_path = os.path.join(PREDICTED_NPZ_DIR, filename)\n",
        "            with np.load(npz_path, allow_pickle=True) as data:\n",
        "                masks = data['masks']\n",
        "                scores = data['scores']\n",
        "                classes = data['classes']\n",
        "                tile_origin_rc = data['tile_origin_rc'] # Pixel origin (r0, c0)\n",
        "                # tile_origin_geo = data['tile_origin_geo'] # Georeferenced origin (x0, y0) - not directly used here but available\n",
        "\n",
        "                if masks is not None and masks.shape[0] > 0:\n",
        "                    # Process each instance mask within the tile\n",
        "                    for i in range(masks.shape[0]):\n",
        "                        instance_mask = masks[i]\n",
        "                        score = scores[i]\n",
        "                        class_id = classes[i]\n",
        "\n",
        "                        # Find contours of the mask\n",
        "                        # cv2.findContours requires a single-channel binary image\n",
        "                        # Ensure instance_mask is uint8 and binary (0 or 255)\n",
        "                        mask_uint8 = instance_mask.astype(np.uint8) * 255\n",
        "                        # Use cv2.RETR_TREE and cv2.CHAIN_APPROX_NONE for more detailed contours if needed,\n",
        "                        # but SIMPLE is usually sufficient for polygons.\n",
        "                        contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                        # Convert contours to polygons and transform coordinates\n",
        "                        for contour in contours:\n",
        "                            # Reshape contour to be a list of points (x, y)\n",
        "                            # Contour points are in tile coordinates (pixel within the tile)\n",
        "                            # Ensure points are in (x, y) format which corresponds to (column, row)\n",
        "                            contour_points_tile = contour.squeeze().tolist()\n",
        "\n",
        "                            if not isinstance(contour_points_tile, list):\n",
        "                                # Handle cases where contour.squeeze() results in a single point\n",
        "                                contour_points_tile = [contour_points_tile]\n",
        "                            elif not all(isinstance(p, list) for p in contour_points_tile):\n",
        "                                # Handle cases where contour.squeeze() results in a flat list of coords\n",
        "                                contour_points_tile = [contour_points_tile]\n",
        "\n",
        "\n",
        "                            if len(contour_points_tile) < 3:\n",
        "                                continue # Skip if not enough points to form a polygon\n",
        "\n",
        "                            # Convert tile pixel coordinates to padded image pixel coordinates\n",
        "                            # Tile origin is (row, col), contour points are (col, row)\n",
        "                            contour_points_padded = [(p[0] + tile_origin_rc[1], p[1] + tile_origin_rc[0]) for p in contour_points_tile]\n",
        "\n",
        "                            # Convert padded image pixel coordinates to geographic coordinates using the original image's transform\n",
        "                            if transform:\n",
        "                                # Apply the affine transform to each point\n",
        "                                # transform * (col, row) gives (x, y) georeferenced coordinates\n",
        "                                contour_points_geo = [transform * (p[0], p[1]) for p in contour_points_padded]\n",
        "                                polygon = Polygon(contour_points_geo)\n",
        "                            else:\n",
        "                                # If no transform, use padded pixel coordinates for the polygon\n",
        "                                polygon = Polygon(contour_points_padded)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                                # Add the polygon and its properties to the vector file\n",
        "                            if not polygon.is_empty and polygon.exterior: # Ensure polygon is valid and not empty\n",
        "                                # Cast score to a standard float type to potentially avoid Fiona warning\n",
        "                                collection.write({\n",
        "                                    'geometry': mapping(polygon),\n",
        "                                    'properties': {'score': float(score), 'class_id': int(class_id)},\n",
        "                                })\n",
        "\n",
        "print(f\"Vector file (Geopackage) saved to {OUTPUT_VECTOR_PATH}\")"
      ],
      "metadata": {
        "id": "9iOIBvZq9XBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "523ea309-8b41-4b52-d1ed-444edf6c6edc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector file (Geopackage) saved to /content/drive/MyDrive/colabDL/TURCHIA4.10/3GEOTIFF410/rubble_predictions_4.gpkg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import rasterio\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "import detectron2.structures\n",
        "import torch # Import torch for tensor operations if masks are included\n",
        "import math # Import math for ceil\n"
      ],
      "metadata": {
        "id": "KLiBdFc0gJvh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import rasterio\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "import detectron2.structures\n",
        "import torch # Import torch for tensor operations if masks are included\n",
        "import math # Import math for ceil\n",
        "\n",
        "# ==== USER PATHS ====\n",
        "# Directory containing the predicted tile .npz files\n",
        "PREDICTED_NPZ_DIR = \"/content/drive/MyDrive/colabDL/TURCHIA4.10/3GEOTIFF410/npz_preds\" # Assuming npz files are in a subdirectory\n",
        "\n",
        "# Path to the original georeferenced image (GeoTIFF or similar)\n",
        "# Needed to get original dimensions and potentially use as background\n",
        "ORIGINAL_GEOREFERENCED_IMAGE_PATH = \"/content/drive/MyDrive/colabDL/TURCHIA4.10/3GEOTIFF410/3_GEOTIFF.tiff\" # Example path, replace with your actual georeferenced image path\n",
        "\n",
        "# Path for the mosaicked output PNG\n",
        "MOSAIC_PNG_PATH = \"/content/drive/MyDrive/colabDL/TURCHIA4.10/3GEOTIFF410/mosaicked_predictions.png\"\n",
        "\n",
        "# Use the same TILE size as used for prediction\n",
        "# You might need to retrieve this from the .npz files or define it here if consistent\n",
        "# For now, assuming TILE = 1024 as in the previous cell\n",
        "TILE = 1024\n",
        "\n",
        "# --- Read the original georeferenced image info ---\n",
        "try:\n",
        "    with rasterio.open(ORIGINAL_GEOREFERENCED_IMAGE_PATH) as src:\n",
        "        orig_h, orig_w = src.shape # Original height and width\n",
        "        # Optionally read the image data if you want to draw on top of it\n",
        "        img_orig = src.read()\n",
        "        img_orig = np.transpose(img_orig, (1, 2, 0))\n",
        "        if img_orig.shape[2] == 4:\n",
        "            img_orig = img_orig[:, :, :3] # Explicitly select first 3 bands\n",
        "except rasterio.errors.RasterioIOError as e:\n",
        "    print(f\"Error reading original georeferenced image info from {ORIGINAL_GEOREFERENCED_IMAGE_PATH}: {e}\")\n",
        "    print(\"Cannot create mosaicked image without original image info.\")\n",
        "    exit() # Exit if original image info cannot be read\n",
        "\n",
        "\n",
        "# --- Determine padded image dimensions and create a blank canvas ---\n",
        "# This logic should match the padding in the tiling cell (cHUiBpUR5Rr3)\n",
        "H_padded = math.ceil(orig_h / TILE) * TILE\n",
        "W_padded = math.ceil(orig_w / TILE) * TILE\n",
        "\n",
        "# Pad the original image to match the dimensions used during tiling\n",
        "pad_bottom = H_padded - orig_h\n",
        "pad_right  = W_padded - orig_w\n",
        "\n",
        "if pad_bottom > 0 or pad_right > 0:\n",
        "    if img_orig.shape[2] == 3:\n",
        "        pad_val = [int(img_orig[-1,-1,0]), int(img_orig[-1,-1,1]), int(img_orig[-1,-1,2])]\n",
        "    else:\n",
        "        pad_val = [0] * img_orig.shape[2] # Should be 3 if we selected bands above\n",
        "    img_padded = cv2.copyMakeBorder(\n",
        "        img_orig, 0, pad_bottom, 0, pad_right,\n",
        "        borderType=cv2.BORDER_CONSTANT, value=pad_val\n",
        "    )\n",
        "else:\n",
        "    img_padded = img_orig\n",
        "\n",
        "# Create a Visualizer using the padded original image as background (convert to BGR)\n",
        "mosaicked_image_bgr = img_padded[:, :, ::-1].copy()\n",
        "\n",
        "\n",
        "# --- Use cfg_pretrained to get the dataset metadata for visualization ---\n",
        "# This requires cfg_pretrained to be defined in a previous cell\n",
        "if 'cfg_pretrained' in globals() and hasattr(cfg_pretrained.DATASETS, 'TRAIN') and cfg_pretrained.DATASETS.TRAIN:\n",
        "    metadata = MetadataCatalog.get(cfg_pretrained.DATASETS.TRAIN[0])\n",
        "else:\n",
        "    # Fallback if cfg_pretrained is not available or doesn't have dataset info\n",
        "    print(\"Warning: Could not retrieve dataset metadata from cfg_pretrained. Using default visualizer settings.\")\n",
        "    metadata = None\n",
        "\n",
        "\n",
        "# Create a Visualizer for the entire padded image\n",
        "v_mosaic = Visualizer(mosaicked_image_bgr, metadata=metadata, scale=1.0)\n",
        "\n",
        "\n",
        "# --- Iterate through collected predictions (.npz files) and draw them ---\n",
        "print(f\"Loading predictions from {PREDICTED_NPZ_DIR} and drawing on mosaicked image...\")\n",
        "\n",
        "npz_filenames = [f for f in os.listdir(PREDICTED_NPZ_DIR) if f.endswith('_pred.npz')]\n",
        "\n",
        "if not npz_filenames:\n",
        "    print(\"No predicted .npz files found in the directory.\")\n",
        "else:\n",
        "    for filename in npz_filenames:\n",
        "        npz_path = os.path.join(PREDICTED_NPZ_DIR, filename)\n",
        "        with np.load(npz_path, allow_pickle=True) as data:\n",
        "            boxes = data['boxes']\n",
        "            scores = data['scores']\n",
        "            classes = data['classes']\n",
        "            masks = data['masks']\n",
        "            tile_origin_rc = data['tile_origin_rc'] # Pixel origin (r0, c0)\n",
        "\n",
        "            # Check if there are any detections (boxes) in this tile\n",
        "            if boxes.shape[0] > 0:\n",
        "                # Create an Instances object for the predictions in this tile\n",
        "                # We need to create a new Instances object with coordinates relative to the padded image\n",
        "                shifted_instances = Instances((H_padded, W_padded))\n",
        "\n",
        "                # Shift boxes\n",
        "                shifted_boxes = Boxes(torch.from_numpy(boxes)) # Convert to tensor\n",
        "                # Boxes are (x1, y1, x2, y2) -> (c1, r1, c2, r2)\n",
        "                shifted_boxes.tensor[:, 0] += tile_origin_rc[1] # shift x1 by c0\n",
        "                shifted_boxes.tensor[:, 1] += tile_origin_rc[0] # shift y1 by r0\n",
        "                shifted_boxes.tensor[:, 2] += tile_origin_rc[1] # shift x2 by c0\n",
        "                shifted_boxes.tensor[:, 3] += tile_origin_rc[0] # shift y2 by r0\n",
        "                shifted_instances.pred_boxes = shifted_boxes\n",
        "\n",
        "                # Copy scores and classes\n",
        "                shifted_instances.scores = torch.from_numpy(scores)\n",
        "                shifted_instances.pred_classes = torch.from_numpy(classes)\n",
        "\n",
        "                # Shift masks - this is more complex and potentially memory intensive\n",
        "                # Add a more robust check for masks not being None and having a valid shape\n",
        "                if masks is not None and isinstance(masks, np.ndarray) and masks.shape[0] > 0 and masks.shape[1:] == (TILE, TILE):\n",
        "                     num_masks = masks.shape[0]\n",
        "                     # Create a temporary tensor to hold the shifted masks\n",
        "                     shifted_masks_tensor = torch.zeros((num_masks, H_padded, W_padded), dtype=torch.bool)\n",
        "                     r0, c0 = tile_origin_rc\n",
        "                     shifted_masks_tensor[:, r0:r0+TILE, c0:c0+TILE] = torch.from_numpy(masks)\n",
        "                     shifted_instances.pred_masks = shifted_masks_tensor # Keep as tensor for Visualizer\n",
        "                else:\n",
        "                     # If no valid masks, explicitly set pred_masks to None or an empty tensor\n",
        "                     shifted_instances.pred_masks = None # Or torch.empty((0, H_padded, W_padded), dtype=torch.bool)\n",
        "\n",
        "\n",
        "                # Draw the shifted instances onto the mosaicked image visualizer\n",
        "                # Visualizer will draw boxes, labels, scores, and masks based on shifted_instances\n",
        "                v_mosaic.draw_instance_predictions(shifted_instances)\n",
        "\n",
        "\n",
        "# Get the final mosaicked image with predictions drawn\n",
        "# Visualizer works in BGR, so convert back to RGB for saving if needed, or save as BGR\n",
        "mosaicked_output_image_bgr = v_mosaic.output.get_image()\n",
        "\n",
        "# Save the mosaicked image\n",
        "cv2.imwrite(MOSAIC_PNG_PATH, mosaicked_output_image_bgr)\n",
        "\n",
        "print(f\"Mosaicked predictions PNG saved to {MOSAIC_PNG_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "6dh_A6bfctlq",
        "outputId": "8ccb5447-58ac-4c8d-8786-2237a957eb88"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading original georeferenced image info from /content/drive/MyDrive/colabDL/TURCHIA4.10/3GEOTIFF410/3_GEOTIFF.tiff: /content/drive/MyDrive/colabDL/TURCHIA4.10/3GEOTIFF410/3_GEOTIFF.tiff: No such file or directory\n",
            "Cannot create mosaicked image without original image info.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'orig_h' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4162271432.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# --- Determine padded image dimensions and create a blank canvas ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# This logic should match the padding in the tiling cell (cHUiBpUR5Rr3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mH_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_h\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mTILE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mTILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mW_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_w\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mTILE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mTILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'orig_h' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SCqAzQ2FhVTl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I2uM3ZzdhVsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tile_tiff_save_preds.py (adapted for PNG output)\n",
        "import os\n",
        "import math\n",
        "import cv2\n",
        "import numpy as np\n",
        "import rasterio # Import rasterio for georeferenced image handling\n",
        "\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog  # needed for Visualizer\n",
        "\n",
        "# ==== USER PATHS ====\n",
        "INPUT_TIFF = \"/content/drive/MyDrive/colabDL/TURCHIA4.10/3GEOTIFF410/3_GEOTIFF.tif\" # Use the georeferenced TIFF\n",
        "OUT_DIR   = \"/content/drive/MyDrive/colabDL/TURCHIA4.10/3GEOTIFF410/predicted_tiles_png\"  # Output directory for predicted tile PNGs\n",
        "TILE = 1024\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Read the georeferenced image and get georeferencing info\n",
        "try:\n",
        "    with rasterio.open(INPUT_TIFF) as src:\n",
        "        img = src.read()\n",
        "        # Rasterio reads bands first (C, H, W), convert to OpenCV format (H, W, C)\n",
        "        img = np.transpose(img, (1, 2, 0))\n",
        "        # Explicitly select the first 3 channels to handle potential alpha channels\n",
        "        if img.shape[2] == 4:\n",
        "            img = img[:, :, :3]\n",
        "        orig_h, orig_w = img.shape[:2]\n",
        "        transform = src.transform # Affine transform for georeferencing\n",
        "        crs = src.crs # Coordinate reference system\n",
        "\n",
        "except rasterio.errors.RasterioIOError as e:\n",
        "    raise FileNotFoundError(f\"Could not read georeferenced image at {INPUT_TIFF}: {e}\")\n",
        "\n",
        "# Pad to multiples of TILE so we don’t lose right/bottom edges\n",
        "H = math.ceil(orig_h / TILE) * TILE\n",
        "W = math.ceil(orig_w / TILE) * TILE\n",
        "pad_bottom = H - orig_h\n",
        "pad_right  = W - orig_w\n",
        "\n",
        "if pad_bottom > 0 or pad_right > 0:\n",
        "    # Use the last pixel value for padding to avoid edge effects if possible,\n",
        "    # otherwise use black padding for color images.\n",
        "    if img.shape[2] == 3:\n",
        "        pad_val = [int(img[-1,-1,0]), int(img[-1,-1,1]), int(img[-1,-1,2])]\n",
        "    else:\n",
        "        pad_val = [0] * img.shape[2]\n",
        "    img_padded = cv2.copyMakeBorder(\n",
        "        img, 0, pad_bottom, 0, pad_right,\n",
        "        borderType=cv2.BORDER_CONSTANT, value=pad_val\n",
        "    )\n",
        "else:\n",
        "    img_padded = img\n",
        "\n",
        "rows = H // TILE\n",
        "cols = W // TILE\n",
        "\n",
        "tiles_written = 0\n",
        "\n",
        "# Use cfg_pretrained to get the dataset metadata for visualization\n",
        "# Check if DATASETS.TRAIN is defined and not empty\n",
        "if 'cfg_pretrained' in globals() and hasattr(cfg_pretrained.DATASETS, 'TRAIN') and cfg_pretrained.DATASETS.TRAIN:\n",
        "    metadata = MetadataCatalog.get(cfg_pretrained.DATASETS.TRAIN[0])\n",
        "else:\n",
        "    metadata = None # Use default metadata if not available\n",
        "\n",
        "\n",
        "for y in range(rows):\n",
        "    for x in range(cols):\n",
        "        r0 = y * TILE\n",
        "        c0 = x * TILE\n",
        "        tile = img_padded[r0:r0+TILE, c0:c0+TILE]\n",
        "\n",
        "        # Make prediction on the tile\n",
        "        outputs = predictor(tile)\n",
        "\n",
        "        # Visualize the predictions on the tile\n",
        "        # Convert tile to BGR for Visualizer\n",
        "        v = Visualizer(tile[:, :, ::-1], metadata=metadata, scale=1.0)\n",
        "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "        predicted_tile = out.get_image()[:, :, ::-1] # Convert back to RGB for saving as PNG\n",
        "\n",
        "        # Save the predicted tile\n",
        "        cv2.imwrite(os.path.join(OUT_DIR, f\"tile_{y}_{x}_pred.png\"), predicted_tile)\n",
        "        tiles_written += 1\n",
        "\n",
        "print(f\"Done. Wrote {tiles_written} predicted tiles to {OUT_DIR}\")"
      ],
      "metadata": {
        "id": "6jyU-88pI_ye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5547f478-1b4c-4fa6-ea86-9f7076dbe447"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. Wrote 110 predicted tiles to /content/drive/MyDrive/colabDL/TURCHIA4.10/3GEOTIFF410/predicted_tiles_png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69ed2b7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91a75854-6507-4d40-ea41-2decdea46db7"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# Directory containing the predicted tiles\n",
        "PREDICTED_TILES_DIR = \"/content/drive/MyDrive/colabDL/TURCHIA4.10/3GEOTIFF410/predicted_tiles_png\"\n",
        "# Output path for the remosaiced image\n",
        "REMOsaICED_OUTPUT_PATH = \"/content/drive/MyDrive/colabDL/TURCHIA4.10/3GEOTIFF410/predicted_mosaic.png\"\n",
        "TILE_SIZE = 1024 # The size of each tile (should match the TILE size used for tiling)\n",
        "\n",
        "# Get all the predicted tile filenames\n",
        "tile_filenames = [f for f in os.listdir(PREDICTED_TILES_DIR) if f.endswith('_pred.png')]\n",
        "\n",
        "if not tile_filenames:\n",
        "    print(\"No predicted tile images found in the directory.\")\n",
        "else:\n",
        "    # Extract rows and columns from filenames to determine the grid size\n",
        "    max_row = 0\n",
        "    max_col = 0\n",
        "    tile_info = {}\n",
        "    for filename in tile_filenames:\n",
        "        match = re.match(r'tile_(\\d+)_(\\d+)_pred\\.png', filename)\n",
        "        if match:\n",
        "            row = int(match.group(1))\n",
        "            col = int(match.group(2))\n",
        "            tile_info[(row, col)] = filename\n",
        "            max_row = max(max_row, row)\n",
        "            max_col = max(max_col, col)\n",
        "\n",
        "    rows = max_row + 1\n",
        "    cols = max_col + 1\n",
        "\n",
        "    # Determine the dimensions of the remosaiced image\n",
        "    # Read one tile to get image dimensions (assuming all tiles have the same dimensions)\n",
        "    sample_tile_path = os.path.join(PREDICTED_TILES_DIR, tile_filenames[0])\n",
        "    sample_tile = cv2.imread(sample_tile_path)\n",
        "    tile_h, tile_w, tile_c = sample_tile.shape\n",
        "\n",
        "    # Calculate the full image dimensions, considering potential padding\n",
        "    # The padded dimensions should match the H and W calculated during tiling\n",
        "    # However, if we saved the predicted tiles without removing the padding visualization,\n",
        "    # the size will be a multiple of TILE_SIZE.\n",
        "    full_h = rows * TILE_SIZE\n",
        "    full_w = cols * TILE_SIZE\n",
        "\n",
        "    # Create a blank canvas for the remosaiced image\n",
        "    remosaiced_img = np.zeros((full_h, full_w, tile_c), dtype=np.uint8)\n",
        "\n",
        "    # Place each tile onto the canvas\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            if (r, c) in tile_info:\n",
        "                tile_filename = tile_info[(r, c)]\n",
        "                tile_path = os.path.join(PREDICTED_TILES_DIR, tile_filename)\n",
        "                tile_img = cv2.imread(tile_path)\n",
        "\n",
        "                # Ensure the tile image size matches the expected TILE_SIZE\n",
        "                if tile_img.shape[:2] == (TILE_SIZE, TILE_SIZE):\n",
        "                     remosaiced_img[r * TILE_SIZE:(r + 1) * TILE_SIZE, c * TILE_SIZE:(c + 1) * TILE_SIZE] = tile_img\n",
        "                else:\n",
        "                     print(f\"Warning: Tile {tile_filename} has unexpected dimensions {tile_img.shape[:2]}. Expected ({TILE_SIZE}, {TILE_SIZE}). Skipping.\")\n",
        "\n",
        "\n",
        "    # Save the remosaiced image\n",
        "    cv2.imwrite(REMOsaICED_OUTPUT_PATH, remosaiced_img)\n",
        "\n",
        "    print(f\"Remosaiced image saved to {REMOsaICED_OUTPUT_PATH}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remosaiced image saved to /content/drive/MyDrive/colabDL/TURCHIA4.10/3GEOTIFF410/predicted_mosaic.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2RrUuZ83hV4k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}